{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "735f64f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2149.47s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: apt-get\n"
     ]
    }
   ],
   "source": [
    "# 한글 폰트 사용을 위한 라이브러리입니다.\n",
    "!apt-get install -y fonts-nanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e88aec49",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m  \u001b[38;5;66;03m# 추가\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m;warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "# utils (먼저 import)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os  # 추가\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "fe = fm.FontEntry(\n",
    "    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n",
    "    name='NanumBarunGothic')\n",
    "fm.fontManager.ttflist.insert(0, fe)\n",
    "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'})\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "import seaborn as sns\n",
    "\n",
    "# Model\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn import metrics\n",
    "from sklearn.compose   import ColumnTransformer\n",
    "from sklearn.pipeline  import Pipeline\n",
    "from category_encoders     import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd146875",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 필요한 데이터를 load 하겠습니다. 경로는 환경에 맞게 지정해주면 됩니다.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../junyub/data/modified_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m test_path  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../junyub/data/modified_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 파일 존재 여부 확인\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 필요한 데이터를 load 하겠습니다. 경로는 환경에 맞게 지정해주면 됩니다.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../junyub/data/modified_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m test_path  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../junyub/data/modified_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 파일 존재 여부 확인\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:768\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:172\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2188\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2185\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2187\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2188\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2190\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2193\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2257\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2255\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2257\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2258\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2260\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 574\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/Downloads/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 필요한 데이터를 load 하겠습니다. 경로는 환경에 맞게 지정해주면 됩니다.\n",
    "train_path = '../junyub/data/modified_train.csv'\n",
    "test_path  = '../junyub/data/modified_test.csv'\n",
    "\n",
    "# 파일 존재 여부 확인\n",
    "if not os.path.exists(train_path):\n",
    "    print(f\"경고: {train_path} 파일이 없습니다. 절대 경로를 확인해주세요.\")\n",
    "if not os.path.exists(test_path):\n",
    "    print(f\"경고: {test_path} 파일이 없습니다. 절대 경로를 확인해주세요.\")\n",
    "\n",
    "dt = pd.read_csv(train_path)\n",
    "dt_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1868f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test 구분을 위한 칼럼을 하나 만들어 줍니다.\n",
    "dt['is_test'] = 0\n",
    "dt_test['is_test'] = 1\n",
    "concat = pd.concat([dt, dt_test])     # 하나의 데이터로 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼럼 이름을 쉽게 바꿔주겠습니다. 다른 칼럼도 사용에 따라 바꿔주셔도 됩니다!\n",
    "concat = concat.rename(columns={'전용면적(㎡)':'전용면적'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db525cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 처럼 아무 의미도 갖지 않는 칼럼은 결측치와 같은 역할을 하므로, np.nan으로 채워 결측치로 인식되도록 합니다.\n",
    "concat['등기신청일자'] = concat['등기신청일자'].replace(' ', np.nan)\n",
    "concat['거래유형'] = concat['거래유형'].replace('-', np.nan)\n",
    "concat['중개사소재지'] = concat['중개사소재지'].replace('-', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b57fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 결측치가 100만개 이하인 변수들만 골라 새로운 concat_select 객체로 저장해줍니다.\n",
    "selected = list(concat.columns[concat.isnull().sum() <= 1000000])\n",
    "concat_select = concat[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a4e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본번, 부번의 경우 float로 되어있지만 범주형 변수의 의미를 가지므로 object(string) 형태로 바꾸어주고 아래 작업을 진행하겠습니다.\n",
    "concat_select['본번'] = concat_select['본번'].astype('str')\n",
    "concat_select['부번'] = concat_select['부번'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6223fbd",
   "metadata": {},
   "source": [
    "여기서 X, Y 좌표 결측치를  채워넣어야 할 것 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y 좌표 결측치 처리\n",
    "print(\"좌표 결측치 현황:\")\n",
    "print(f\"좌표X 결측치: {concat_select['좌표X'].isnull().sum()}\")\n",
    "print(f\"좌표Y 결측치: {concat_select['좌표Y'].isnull().sum()}\")\n",
    "\n",
    "# 좌표가 결측인 경우 해당 행 제거 (학교/패스트푸드 피쳐 생성에 필요)\n",
    "concat_select = concat_select.dropna(subset=['좌표X', '좌표Y'])\n",
    "print(f\"좌표 결측치 제거 후 데이터 크기: {concat_select.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저, 연속형 변수와 범주형 변수를 위 info에 따라 분리해주겠습니다.\n",
    "continuous_columns = []\n",
    "categorical_columns = []\n",
    "\n",
    "for column in concat_select.columns:\n",
    "    if pd.api.types.is_numeric_dtype(concat_select[column]):\n",
    "        continuous_columns.append(column)\n",
    "    else:\n",
    "        categorical_columns.append(column)\n",
    "\n",
    "print(\"연속형 변수:\", continuous_columns)\n",
    "print(\"범주형 변수:\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수에 대한 보간\n",
    "concat_select[categorical_columns] = concat_select[categorical_columns].fillna('NULL')\n",
    "\n",
    "# 연속형 변수에 대한 보간 (선형 보간)\n",
    "concat_select[continuous_columns] = concat_select[continuous_columns].interpolate(method='linear', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faadebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 제거 방법에는 IQR을 이용하겠습니다.\n",
    "def remove_outliers_iqr(dt, column_name):\n",
    "    df = dt.query('is_test == 0')       # train data 내에 있는 이상치만 제거하도록 하겠습니다.\n",
    "    df_test = dt.query('is_test == 1')\n",
    "\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    df = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
    "\n",
    "    result = pd.concat([df, df_test])   # test data와 다시 합쳐주겠습니다.\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 방법으로 전용 면적에 대한 이상치를 제거해보겠습니다.\n",
    "concat_select = remove_outliers_iqr(concat_select, '전용면적')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시군구, 년월 등 분할할 수 있는 변수들은 세부사항 고려를 용이하게 하기 위해 모두 분할해 주겠습니다.\n",
    "def split_address(address):\n",
    "    try:\n",
    "        parts = address.split()\n",
    "        if len(parts) >= 3:\n",
    "            return parts[1], parts[2]  # 구, 동\n",
    "        else:\n",
    "            return '기타', '기타'\n",
    "    except:\n",
    "        return '기타', '기타'\n",
    "\n",
    "concat_select[['구', '동']] = concat_select['시군구'].apply(\n",
    "    lambda x: pd.Series(split_address(x))\n",
    ")\n",
    "del concat_select['시군구']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강남 여부를 표시하는 피쳐를 생성합니다.\n",
    "\n",
    "all = list(concat_select['구'].unique())\n",
    "gangnam = ['강서구', '영등포구', '동작구', '서초구', '강남구', '송파구', '강동구']\n",
    "gangbuk = [x for x in all if x not in gangnam]\n",
    "\n",
    "assert len(all) == len(gangnam) + len(gangbuk)       # 알맞게 분리되었는지 체크합니다.\n",
    "\n",
    "is_gangnam = []\n",
    "for x in concat_select['구'].tolist() :\n",
    "  if x in gangnam :\n",
    "    is_gangnam.append(1)\n",
    "  else :\n",
    "    is_gangnam.append(0)\n",
    "\n",
    "# 파생변수를 하나 만듭니다.\n",
    "concat_select['강남여부'] = is_gangnam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ecdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_select.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358876f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 계약년, 계약월 변수 생성 후, 학습 데이터의 최초 기간부터 경과한 기간을 계산합니다.\n",
    "\n",
    "concat_select['계약년'] = (\n",
    "    concat_select['계약년월']\n",
    "    .astype(str)\n",
    "    .str[:4]\n",
    "    .astype(int)\n",
    ")\n",
    "concat_select['계약월'] = (\n",
    "    concat_select['계약년월']\n",
    "    .astype(str)\n",
    "    .str[4:6]\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "concat_select.drop(columns='계약년월', inplace=True)\n",
    "\n",
    "BASE_YEAR  = 2007\n",
    "BASE_MONTH = 1\n",
    "\n",
    "concat_select['거래개월수'] = (\n",
    "    (concat_select['계약년']  - BASE_YEAR) * 12\n",
    "  + (concat_select['계약월'] - BASE_MONTH)\n",
    ")\n",
    "\n",
    "concat_select['거래개월수'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf289e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 건축년도를 사용하여 건축연수라는 새로운 피쳐를 생성합니다.\n",
    "\n",
    "# 1) 연도 계산용 기준 년도 설정\n",
    "CURRENT_YEAR = 2025\n",
    "\n",
    "# 2) '건축연수' 파생변수 생성\n",
    "#    concat_select 혹은 원하는 DataFrame 이름으로 바꿔서 쓰세요.\n",
    "concat_select['건축연수'] = CURRENT_YEAR - concat_select['건축년도'].astype(int)\n",
    "\n",
    "# 3) 확인\n",
    "print(concat_select[['건축년도','건축연수']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a0549",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 부동산 데이터와 패스트푸드점 데이터의 좌표를 사용하여 \"반경 1km 내에 패스트푸드점 갯수\" 피쳐를 생성합니다.\n",
    "\n",
    "fastfood_file = 'kakao_burger_all_seoul.csv'\n",
    "if os.path.exists(fastfood_file):\n",
    "    fastfood_branches = pd.read_csv(fastfood_file, encoding='utf-8')\n",
    "    \n",
    "    # address 에서 \"○○구\", \"○○동\" 추출하기 (정규식)\n",
    "    fastfood_branches['구'] = fastfood_branches['address_name'].str.extract(r'(\\w+구)')\n",
    "    fastfood_branches['동'] = fastfood_branches['address_name'].str.extract(r'(\\w+동)')\n",
    "    \n",
    "    print(f\"패스트푸드 데이터 로드 완료: {len(fastfood_branches)}개\")\n",
    "    print(fastfood_branches.head(10))\n",
    "else:\n",
    "    print(f\"경고: {fastfood_file} 파일이 없습니다. 패스트푸드 피쳐를 0으로 설정합니다.\")\n",
    "    # 기본값 설정\n",
    "    concat_select['Lot_Mst_within_1km'] = 0\n",
    "    concat_select['Mc_KFC_BK_within_1km'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패스트푸드 파일이 존재할 때만 실행\n",
    "if os.path.exists(fastfood_file):\n",
    "    # 1) pick out the two groups of brands\n",
    "    group1 = ['롯데리아', '맘스터치']\n",
    "    group2 = ['맥도날드', 'KFC', '버거킹']\n",
    "\n",
    "    df1 = fastfood_branches[fastfood_branches['brand'].isin(group1)]\n",
    "    df2 = fastfood_branches[fastfood_branches['brand'].isin(group2)]\n",
    "\n",
    "    # 2) build BallTrees (haversine expects lat/lon in radians)\n",
    "    br1 = np.deg2rad(df1[['lat','lng']].values)\n",
    "    br2 = np.deg2rad(df2[['lat','lng']].values)\n",
    "\n",
    "    tree1 = BallTree(br1, metric='haversine')\n",
    "    tree2 = BallTree(br2, metric='haversine')\n",
    "\n",
    "    # 3) prepare apartment coords\n",
    "    apt_coords = np.deg2rad(concat_select[['좌표Y','좌표X']].values)\n",
    "\n",
    "    # 4) query radius = 1km → radians on earth\n",
    "    earth_r = 6_371_000  # metres\n",
    "    rad = 1_000 / earth_r\n",
    "\n",
    "    idxs1 = tree1.query_radius(apt_coords, r=rad)\n",
    "    idxs2 = tree2.query_radius(apt_coords, r=rad)\n",
    "\n",
    "    # 5) count and assign\n",
    "    concat_select['Lot_Mst_within_1km']    = [len(idx) for idx in idxs1]\n",
    "    concat_select['Mc_KFC_BK_within_1km'] = [len(idx) for idx in idxs2]\n",
    "\n",
    "    print(\"패스트푸드 피쳐 생성 완료\")\n",
    "    print(concat_select.head(10))\n",
    "else:\n",
    "    print(\"패스트푸드 파일이 없어서 피쳐 생성을 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 주변 중학교의 학업성취도 관련한 피쳐를 생성합니다. \n",
    "school_file = 'middle_schools_with_coords_and_roadaddr.csv'\n",
    "\n",
    "if os.path.exists(school_file):\n",
    "    df_sch = pd.read_csv(school_file, encoding='utf-8-sig').dropna(subset=['학업성취도','X좌표(경도)','Y좌표(위도)'])\n",
    "    \n",
    "    # float 변환\n",
    "    df_sch['X좌표(경도)'] = df_sch['X좌표(경도)'].astype(float)\n",
    "    df_sch['Y좌표(위도)'] = df_sch['Y좌표(위도)'].astype(float)\n",
    "    \n",
    "    # 2) BallTree 준비\n",
    "    school_coords = np.deg2rad(df_sch[['Y좌표(위도)','X좌표(경도)']].values)\n",
    "    school_achv   = df_sch['학업성취도'].values\n",
    "    tree = BallTree(school_coords, metric='haversine')\n",
    "    \n",
    "    # 3) 아파트 좌표 준비\n",
    "    concat_select['좌표X'] = concat_select['좌표X'].astype(float)\n",
    "    concat_select['좌표Y'] = concat_select['좌표Y'].astype(float)\n",
    "    apt_coords = np.deg2rad(concat_select[['좌표Y','좌표X']].values)\n",
    "    \n",
    "    # 4) 반경 설정: 2km → radians\n",
    "    earth_r = 6_371_000\n",
    "    radius  = 2_000 / earth_r\n",
    "    \n",
    "    # 5) 피쳐 저장용 리스트\n",
    "    mean_achv     = []\n",
    "    max_achv      = []\n",
    "    count_schools = []\n",
    "    wmean_achv    = []\n",
    "    \n",
    "    # 6) 아파트 한 건씩 쿼리\n",
    "    for coord in apt_coords:\n",
    "        inds, dists = tree.query_radius(coord.reshape(1,-1), \n",
    "                                        r=radius, \n",
    "                                        return_distance=True)\n",
    "        inds = inds[0]\n",
    "        dists = dists[0]\n",
    "        if inds.size == 0:\n",
    "            mean_achv.append(0)  # NaN 대신 0으로 변경\n",
    "            max_achv.append(0)   # NaN 대신 0으로 변경\n",
    "            count_schools.append(0)\n",
    "            wmean_achv.append(0) # NaN 대신 0으로 변경\n",
    "        else:\n",
    "            achvs = school_achv[inds]\n",
    "            mean_achv.append(achvs.mean())\n",
    "            max_achv.append(achvs.max())\n",
    "            count_schools.append(len(inds))\n",
    "            w = 1.0 / (dists + 1e-6)\n",
    "            wmean_achv.append((achvs * w).sum() / w.sum())\n",
    "    \n",
    "    # 7) concat_select 에 컬럼 추가\n",
    "    concat_select['school_mean_2km']  = mean_achv\n",
    "    concat_select['school_max_2km']   = max_achv\n",
    "    concat_select['school_cnt_2km']   = count_schools\n",
    "    concat_select['school_wmean_2km'] = wmean_achv\n",
    "    \n",
    "    print(\"학교 데이터 피쳐 생성 완료\")\n",
    "    print(concat_select[['school_mean_2km','school_max_2km',\n",
    "                         'school_cnt_2km','school_wmean_2km']].head())\n",
    "else:\n",
    "    print(f\"경고: {school_file} 파일이 없습니다. 학교 관련 피쳐를 0으로 설정합니다.\")\n",
    "    concat_select['school_mean_2km'] = 0\n",
    "    concat_select['school_max_2km'] = 0\n",
    "    concat_select['school_cnt_2km'] = 0\n",
    "    concat_select['school_wmean_2km'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4f25c1",
   "metadata": {},
   "source": [
    "추후 강남역, 버스 및 지하철과의 근접도를 고려하는 피쳐도 추가할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_select.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3개 모델 앙상블을 적용한 인코딩 및 학습을 실시합니다.\n",
    "\n",
    "# 1) 모델 학습에 활용할 컬럼만 남깁니다.\n",
    "keep_cols = [\n",
    "    '계약년',\n",
    "    '계약월', \n",
    "    '거래개월수',\n",
    "    '전용면적',\n",
    "    '구',\n",
    "    '동',\n",
    "    '도로명',\n",
    "    '강남여부',\n",
    "    '아파트명',\n",
    "    '건축연수',\n",
    "    'Lot_Mst_within_1km',\n",
    "    'Mc_KFC_BK_within_1km',\n",
    "    'school_mean_2km',\n",
    "    'school_max_2km',\n",
    "    'school_cnt_2km',\n",
    "    'school_wmean_2km',\n",
    "    'is_test',\n",
    "    'target'\n",
    "]\n",
    "\n",
    "# 2) 선택된 컬럼으로 데이터 준비\n",
    "df_selected = concat_select[keep_cols].copy()\n",
    "\n",
    "# 3) 모델 학습을 위해 학습 데이터와 테스트 데이터를 분할하고, TimeSeriesSplit 을 위해 시계열 순서대로 정렬\n",
    "dt_train = df_selected.query(\"is_test == 0\") \\\n",
    "                     .sort_values(\"거래개월수\") \\\n",
    "                     .reset_index(drop=True)\n",
    "dt_test  = df_selected.query(\"is_test == 1\") \\\n",
    "                     .reset_index(drop=True)\n",
    "\n",
    "# 4) Target Log Transformation 적용\n",
    "print(\"Log transformation 전 target 분포:\")\n",
    "print(dt_train['target'].describe())\n",
    "print(f\"Skewness: {dt_train['target'].skew():.3f}\")\n",
    "\n",
    "dt_train['target_log'] = np.log1p(dt_train['target'])\n",
    "\n",
    "print(\"\\nLog transformation 후 target 분포:\")\n",
    "print(dt_train['target_log'].describe())\n",
    "print(f\"Skewness: {dt_train['target_log'].skew():.3f}\")\n",
    "\n",
    "# 5) 연속형 변수와 범주형 변수 분리\n",
    "continuous_columns_v2 = []\n",
    "categorical_columns_v2 = []\n",
    "\n",
    "for col in dt_train.columns:\n",
    "    if pd.api.types.is_numeric_dtype(dt_train[col]) \\\n",
    "    or pd.api.types.is_datetime64_any_dtype(dt_train[col]):\n",
    "        continuous_columns_v2.append(col)\n",
    "    else:\n",
    "        categorical_columns_v2.append(col)\n",
    "\n",
    "# 범주형 변수: 결측을 'NA'로, 모두 문자열(str)로 변환\n",
    "for df in (dt_train, dt_test):\n",
    "    for c in categorical_columns_v2:\n",
    "        df[c] = df[c].fillna(\"NA\").astype(str)\n",
    "\n",
    "print(\"연속형 변수:\", continuous_columns_v2)\n",
    "print(\"범주형 변수:\", categorical_columns_v2)\n",
    "\n",
    "# 6) 전처리기 정의 (범주형 → Ordinal, 나머지 passthrough)\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"ord\", OrdinalEncoder(\n",
    "          handle_unknown=\"use_encoded_value\",\n",
    "          unknown_value=-1\n",
    "     ), categorical_columns_v2),\n",
    "],\n",
    "remainder=\"passthrough\")\n",
    "\n",
    "# 7) 3개 모델 파이프라인 정의\n",
    "models = {\n",
    "    \"RF\"   : Pipeline([(\"preprocessor\", preprocessor),\n",
    "                       (\"model\", RandomForestRegressor(n_estimators=100, random_state=42))]),\n",
    "    \"LGBM\" : Pipeline([(\"preprocessor\", preprocessor),\n",
    "                       (\"model\", lgb.LGBMRegressor(n_estimators=200, random_state=42))]),\n",
    "    \"CB\"   : Pipeline([(\"preprocessor\", preprocessor),\n",
    "                       (\"model\", CatBoostRegressor(verbose=0, random_state=42))]),\n",
    "}\n",
    "\n",
    "# 8) 시계열 교차검증으로 각 모델 성능 평가\n",
    "X = dt_train[continuous_columns_v2 + categorical_columns_v2]\n",
    "y = dt_train[\"target_log\"]\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "results = {}\n",
    "for name, pipe in models.items():\n",
    "    scores = cross_val_score(pipe, X, y,\n",
    "                             cv=tscv,\n",
    "                             scoring=\"neg_mean_squared_error\",\n",
    "                             n_jobs=-1)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    results[name] = rmse_scores\n",
    "    print(f\"{name}  RMSE per fold: {rmse_scores}\")\n",
    "    print(f\"{name}  Mean RMSE: {rmse_scores.mean():.2f}\\n\")\n",
    "\n",
    "# 9) 세 모델을 모두 학습한 뒤, 테스트셋에 대해 예측하고 단순 평균 앙상블\n",
    "X_test = dt_test[continuous_columns_v2 + categorical_columns_v2]\n",
    "\n",
    "preds = []\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X, y)\n",
    "    preds.append(pipe.predict(X_test))\n",
    "\n",
    "# 10) 평균 예측\n",
    "ensemble_pred_log = np.mean(preds, axis=0)\n",
    "\n",
    "# 11) 실제 단위로 변환\n",
    "ensemble_pred = np.expm1(ensemble_pred_log)\n",
    "\n",
    "# 12) 결과를 output.csv 로 저장\n",
    "output = pd.DataFrame({\n",
    "    \"target\": ensemble_pred\n",
    "}, index=dt_test.index)\n",
    "\n",
    "output.to_csv(\"output.csv\", index=False)\n",
    "print(\"✅ 앙상블 예측값을 output.csv 에 저장했습니다.\")\n",
    "\n",
    "# 13) 실제 단위(RMSE)로 변환해서 평가\n",
    "real_rmse_list = []\n",
    "for train_idx, test_idx in tscv.split(X):\n",
    "    X_train, X_test_cv = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test_cv = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # 각 모델별 예측\n",
    "    preds_cv = []\n",
    "    for name, pipe in models.items():\n",
    "        pipe.fit(X_train, y_train)\n",
    "        preds_cv.append(pipe.predict(X_test_cv))\n",
    "    \n",
    "    # 앙상블 예측\n",
    "    ensemble_pred_log_cv = np.mean(preds_cv, axis=0)\n",
    "    ensemble_pred_cv = np.expm1(ensemble_pred_log_cv)\n",
    "    y_true_cv = np.expm1(y_test_cv)\n",
    "    \n",
    "    rmse = mean_squared_error(y_true_cv, ensemble_pred_cv, squared=False)\n",
    "    real_rmse_list.append(rmse)\n",
    "\n",
    "print(\"각 fold 실제 RMSE:\", real_rmse_list)\n",
    "print(\"평균 실제 RMSE:\", np.mean(real_rmse_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
